# PlaNet-RL

A PyTorch implementation of a simplified PlaNet (Planning Network) agent trained on the CartPole-v1 environment. This project replicates the core components of the PlaNet architecture including a Recurrent State-Space Model (RSSM), latent-space planning, and variational sequence modeling.

---

## ğŸ§  Project Highlights

- Implements core ideas from the PlaNet paper in a modular fashion
- Uses a recurrent latent model (RSSM) to learn compact world models
- Performs model-based planning using latent rollouts

---

## ğŸ“ Folder Structure

```
PlaNet-RL/
â”‚
â”œâ”€â”€ model/             # Core neural network components
â”‚   â”œâ”€â”€ encoder.py
â”‚   â”œâ”€â”€ rssm.py
â”‚   â””â”€â”€ decoder.py
â”‚
â”œâ”€â”€ agent/             # Planning agent logic
â”‚   â”œâ”€â”€ planner.py
â”‚   â””â”€â”€ agent.py
â”‚
â”œâ”€â”€ envs/              # Environment loader
â”‚   â””â”€â”€ make_env.py
â”‚
â”œâ”€â”€ train.py           # Training loop
â”œâ”€â”€ test.py            # Evaluation and GIF rendering
â”œâ”€â”€ utils.py           # Replay buffer, logging, utilities
â”œâ”€â”€ config.yaml        # Config file
â”œâ”€â”€ README.md          # Project documentation
â”œâ”€â”€ .gitignore         # Ignore config/logs/pycache
â”œâ”€â”€ training.log       # Mock training logs
â””â”€â”€ results/
    â”œâ”€â”€ rewards_plot.png
    â””â”€â”€ sample_episode.gif
```

---

## ğŸš€ Training

```bash
python train.py
```

Training logs and reward plots will be saved to `training.log` and `results/` respectively.

---

## ğŸ“Š Evaluation

```bash
python test.py
```

This will generate a `sample_episode.gif` visualizing an episode played by the trained agent.

---

## ğŸ“¦ Requirements

- Python 3.8+
- PyTorch >= 1.10
- Gym >= 0.21
- imageio

Install requirements:
```bash
pip install -r requirements.txt
```

---

## âœï¸ Author

This project was independently implemented and tested locally for research and educational purposes.
